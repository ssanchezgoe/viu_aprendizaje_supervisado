{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqc9iSEY2ow7LnOfx1PP5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/tema4/aprendizaje_supervisado_tema4_modelo_regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdQoM_Qq408t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X = df['ENGINESIZE'].values.reshape(-1,1)\n",
        "y = df['CO2EMISSIONS'].values"
      ],
      "metadata": {
        "id": "Qgl04Y825Qk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.scatter(X_test, y_test,  color='black',label=r'datos test')\n",
        "plt.scatter(X, y,  color='red',alpha=0.4,label=r'datos entrenamiento')"
      ],
      "metadata": {
        "id": "SSShBQPII7gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir 0.2 test y fijar semilla aleatoria\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "r2ozvpyG6Lry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Max X_train {X_train.max()}, Min X_train {X_train.min()}')"
      ],
      "metadata": {
        "id": "orGXPAnZ6RDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estandarización de los datos de entrenamiento y test\n",
        "std_scaling = preprocessing.StandardScaler()\n",
        "\n",
        "X_train = std_scaling.fit_transform(X_train)\n",
        "X_test = std_scaling.transform(X_test)"
      ],
      "metadata": {
        "id": "VQ7S_nE56dMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Max X_train {X_train.max()}, Min X_train {X_train.min()}')"
      ],
      "metadata": {
        "id": "dT-WA56h7Ypw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas de evaluación.\n",
        "metricas = {\n",
        "  'MAE': 'neg_mean_absolute_error',\n",
        "  'MSE': 'neg_mean_squared_error',\n",
        "  'R2' : 'r2',\n",
        "  'RMSE': make_scorer(lambda y, y_pred:\n",
        "                      sqrt(mean_squared_error(y, y_pred)),\n",
        "                      greater_is_better=False),\n",
        "  'MAPE': make_scorer(lambda y, y_pred:\n",
        "                      np.mean(np.abs((y - y_pred) / y)) * 100,\n",
        "                      greater_is_better=False)}"
      ],
      "metadata": {
        "id": "GCGU6zgX7b8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regresión lineal\n",
        "# Definimos un algoritmo LR de regresión\n",
        "algorithm = LinearRegression(fit_intercept=True)"
      ],
      "metadata": {
        "id": "OyEfTLCz9AfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación y evaluación del modelo.\n",
        "# en \"cv = KFold(n_splits=5)\" se hace un cross-validation INTERNO!!\n",
        "results = cross_validate(algorithm, X_train, y_train, cv = KFold(n_splits=5, shuffle=True, random_state=42), scoring=metricas)\n",
        "# Presentación de los resultados de la evaluación.\n",
        "pprint(results)"
      ],
      "metadata": {
        "id": "pnABRYTY9Sd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un algoritmo SVM de regresión candidato\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model = model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xwXL7osr9T0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAE en el conjunto de test\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'Test results (MAE) {mae}')"
      ],
      "metadata": {
        "id": "2gqb5x0wA2-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_test, y_test,  color='black',label=r'datos test')\n",
        "plt.scatter(X_train, y_train,  color='red',alpha=0.4,label=r'datos entrenamiento')\n",
        "plt.plot(X_test, y_pred, color='blue',label=r'predicción')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(r'Engine size')\n",
        "plt.ylabel(r'CO2EMISSIONS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jSKmo3DjBFgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar modelo\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "s1-gKxR8BHdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "vnT1eMkGNvMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "B7MY4czsSbOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "# Definimos un algoritmo SVM de regresión\n",
        "algorithm = KNeighborsRegressor(n_neighbors=10, weights='distance')"
      ],
      "metadata": {
        "id": "7wbRDDhNkZvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación y evaluación del modelo.\n",
        "# en \"cv = KFold(n_splits=5)\" se hace un cross-validation INTERNO!!\n",
        "results = cross_validate(algorithm, X_train, y_train, cv = KFold(n_splits=5, shuffle=True, random_state=42), scoring=metricas)\n",
        "# Presentación de los resultados de la evaluación.\n",
        "pprint(results)"
      ],
      "metadata": {
        "id": "AhNzb7M_kNz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Vecinos\n",
        "knn = KNeighborsRegressor(n_neighbors=2, weights='distance')\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "CGBBzP5-jRWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAE en el conjunto de test\n",
        "y_pred = knn.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'Test results (MAE) {mae}')"
      ],
      "metadata": {
        "id": "KtwKDxjCjsW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearch\n",
        "# Parameters\n",
        "parameters = {'n_neighbors':np.arange(1,15), 'weights':('uniform', 'distance'), 'metric':('euclidean', 'cosine', 'manhattan')}\n",
        "reg = KNeighborsRegressor()\n",
        "\n",
        "model = GridSearchCV(reg, parameters, scoring='r2')\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ByFUlPo2j-o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mejor conjunto de parámetros:\")\n",
        "print()\n",
        "print(model.best_params_)\n",
        "print()\n",
        "print(\"Media y desviación:\")\n",
        "print()\n",
        "means = model.cv_results_['mean_test_score']\n",
        "stds = model.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "          % (mean, std * 2, params))"
      ],
      "metadata": {
        "id": "4fqVujYgscql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regresion Lineal Múltiple\n",
        "\n",
        "archivo = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/automobileEDA.csv'\n",
        "df = pd.read_csv(archivo)\n",
        "\n",
        "X = df[['engine-size','curb-weight']]\n",
        "y = df['price']"
      ],
      "metadata": {
        "id": "_xerZY4uxqnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir 0.2 test y fijar semilla aleatoria\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EIjjnP57zMl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estandarización de los datos de entrenamiento y test\n",
        "std_scaling = preprocessing.StandardScaler()\n",
        "\n",
        "X_train = std_scaling.fit_transform(X_train)\n",
        "X_test = std_scaling.transform(X_test)"
      ],
      "metadata": {
        "id": "PN1J_DtwzRtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un algoritmo SVM de regresión candidato\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model = model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "P8UKIXT9zfIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAE en el conjunto de test\n",
        "y_pred = model.predict(X_test)\n",
        "r2_metric = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Test results (MAE) {r2_metric}')"
      ],
      "metadata": {
        "id": "365HTtaWzjlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N59YXM5Cq7t"
      },
      "source": [
        "\n",
        "#### Regresión Ridge\n",
        "<p><a name=\"ridge\"></a></p>\n",
        "\n",
        "En éste típo de algorítmo se impondrá una penalidad sobre los coeficientes calculados, de tal manera que se modificará el error de los mínimos cuadrados como:\n",
        "\n",
        "$$\\sum (Y_i-\\hat Y_i)^2+\\alpha \\sum w_i^2 $$\n",
        "\n",
        "\n",
        "El hiperparámetro $\\alpha$, llamado complejidad, controla qué tanto se penaliza los coeficientes, haciendo que éstos sean más pequeños y por tanto estabilizando las soluciones aunque a costa de una menor sesibilidad a los datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XYnP6-PSK9e"
      },
      "source": [
        "Para comparar entrenemos un modelo LinearRegresor y uno Ridge con todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaRNw-BIO9Dv"
      },
      "source": [
        "df.dropna(inplace=True)\n",
        "X = df[['symboling', 'normalized-losses', 'wheel-base', 'length',\n",
        "       'width', 'height', 'curb-weight',\n",
        "       'engine-size', 'bore', 'stroke', 'compression-ratio',\n",
        "       'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg',\n",
        "       'city-L/100km',  'diesel', 'gas']]\n",
        "y = df['price']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8UW-ctON4WJ"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=3)\n",
        "\n",
        "# Estandarización de los datos de entrenamiento y test\n",
        "std_scaling = preprocessing.StandardScaler()\n",
        "\n",
        "X_train = std_scaling.fit_transform(X_train)\n",
        "X_test = std_scaling.transform(X_test)\n",
        "\n",
        "#modelo OLS\n",
        "linearM  = LinearRegression()\n",
        "linearM.fit(X_train,y_train)\n",
        "print('R2 OLS =',linearM.score(X_test,y_test))\n",
        "print('wi OLS =',linearM.coef_)\n",
        "print('w0 OLS =',linearM.intercept_)\n",
        "\n",
        "#Modelo Ridge\n",
        "print(5*'#')\n",
        "ridge  = Ridge(alpha=1)\n",
        "ridge.fit(X_train,y_train)\n",
        "print('R2 Ridge =',ridge.score(X_test,y_test))\n",
        "print('wi Ridge =',ridge.coef_)\n",
        "print('w0 Ridge =',ridge.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4QF7mJQXCLq"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(ridge.coef_,'r.-',label=r'Coeficientes Ridge')\n",
        "plt.plot(linearM.coef_,'b*',label=r'Coeficientes OLS')\n",
        "plt.legend()\n",
        "plt.xlabel(r'Coeficiente')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAuu5y2PTbDE"
      },
      "source": [
        "Vemos que en el caso del dataset para autos con un valor de $\\alpha = 1$ se nota una pequeña variación en los parámetros y la precisión del modelo.\n",
        "\n",
        "El modelo se hace robusto a variaciones de los predictores, pero puerde un poco de precisión (se necesitan más datos para entrenamiento)\n",
        "\n",
        "En general el hiperparámetro $\\alpha$ debe ser  buscado con varios experimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eQq2bxZZGA0"
      },
      "source": [
        "#### Regresión Lasso\n",
        "<p><a name=\"lasso\"></a></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McFBYtFpZQJK"
      },
      "source": [
        "Al igual que el algorítmo Ridge, Lasso impone una penalidad sobre la función de error del OLS, pero ésta en cambio está dada por el valor absoluto de los coeficientes, así:\n",
        "$$\\sum (Y_i-\\hat Y_i)^2+\\alpha \\sum |w_i|$$\n",
        "\n",
        "Esto hace que a diferencia de Ridge que buscaba hacer pequeños los valores de algunos $w_i$, Lasso fuerza a que sean 0.\n",
        "\n",
        "Así, puede decirse que Ridge es bueno cuando esperamos que todos los predictores tengan una influencia sobre el predictor así sea pequeña, mientras que Lasso se usará cuando esperamos que el numero de predictores relevantes sea pequeño (predictores con peso diferente de 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6AFGzbGao2p"
      },
      "source": [
        "Para implementar una regresión tipo Lasso se sigue el mismo esquema de los casos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqNbFWnAb2we"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "#modelo Lasso\n",
        "lasso  = Lasso(alpha=100)\n",
        "lasso.fit(X_train,y_train)\n",
        "print('R2 Lasso =',lasso.score(X_test,y_test))\n",
        "print('wi Lasso =',lasso.coef_)\n",
        "print('w0 Lasso =',lasso.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWvDHtaIcVBT"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(lasso.coef_,'r.-',label=r'Coeficientes Lasso')\n",
        "plt.plot(linearM.coef_,'b*',label=r'Coeficientes OLS')\n",
        "plt.plot(ridge.coef_,'g*',label=r'Coeficientes Ridge')\n",
        "plt.legend()\n",
        "plt.xlabel(r'Coeficiente')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7SNd4NIdKGS"
      },
      "source": [
        "print('numero de coeficientes:',len(linearM.coef_))\n",
        "print('numero de coeficientes diferentes a cero para Ridge:',len(ridge.coef_[ridge.coef_!=0]))\n",
        "print('numero de coeficientes diferentes a cero para Lasso:',len(lasso.coef_[lasso.coef_!=0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1mHxmRsS5guH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3O4ISooUlm_"
      },
      "source": [
        "#### Redes elásticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNw4dr2v2tsV"
      },
      "source": [
        "Como vimos anteriormente, podemos generar penalizaciones a las regresiones lineales haciendo cambios en su metrica de error.\n",
        "\n",
        "Para la regresión Ridge se penaliza con: $\\alpha \\sum w_i^2$ (penalidad $L_2$), mientras que para Lasso se tiene que:\n",
        "$\\alpha \\sum |w_i|$ (penalidad $L_1$). Cada una de ellas tenía sus pro y sus contra. Pero es posible hacer una combinación de ambos metodos.\n",
        "\n",
        "A las regresiones que usan una combinación de ambas penalidades se les conoce como **ElasticNet** (Redes elásticas) y definimos su error como:\n",
        "$$\\sum (Y_i- \\hat Y_i)^2+\\alpha \\rho \\sum |w_i| + \\frac{\\alpha(1-\\rho)}{2}\\sum w_i^2. $$\n",
        "\n",
        "Note que cuando $ \\rho=1$ tenemos la regresión Lasso, y con $\\rho=0$ tendremos la de Ridge, por tanto en las redes elásticas $0\\leq \\rho\\leq1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU8NhFaQ-UHB"
      },
      "source": [
        "Hemos dado un paso más en la complejización del modelo ya que ahora debemos preocuparnos por el ajuste de 2 hiperparámetros para seleccionar el mejor modelo.\n",
        "\n",
        "Para usar las redes elásticas en sklearn debemos importar la función 'ElasticNet' del modulo de modelos lineales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9KmzhnX-MOs"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5gRbxEi_eZg"
      },
      "source": [
        "En la implementación de sklearn tenemos los hiperparámetros 'alpha' y 'l1_ratio' ($\\rho$ en nuestra ecuación), con ellos controlaremos el comportamiento del regresor.\n",
        "\n",
        "Tenga en cuenta que para valores de *l1_ratio* $\\leq0.01$ el algoritmo de sklearn no es estable si usamos el valor de $\\alpha$ por defecto y se hace necesario que nosotros mísmos ajustemos el valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMTIOIlLAnZ4"
      },
      "source": [
        "df=pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X = df['ENGINESIZE'].values.reshape(-1,1)\n",
        "y = df['CO2EMISSIONS'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U7_NsiKA-L9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn import metrics\n",
        "\n",
        "#seleccionamos los datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=3)\n",
        "\n",
        "# Estandarización de los datos de entrenamiento y test\n",
        "std_scaling = preprocessing.StandardScaler()\n",
        "\n",
        "X_train = std_scaling.fit_transform(X_train)\n",
        "X_test = std_scaling.transform(X_test)\n",
        "\n",
        "\n",
        "#entrenamos el modelo\n",
        "elastic = ElasticNet(alpha=0.01,l1_ratio=1)\n",
        "elastic.fit(X_train,y_train)\n",
        "y_pred = elastic.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFNqiFJxBuQg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X_test, y_test,  color='black',label=r'datos test')\n",
        "plt.scatter(X_train, y_train,  color='red',alpha=0.4,label=r'datos entrenamiento')\n",
        "plt.plot(X_test, y_pred, color='blue',label=r'predicción')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(r'Engine size')\n",
        "plt.ylabel(r'Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOD-5UQ_CCce"
      },
      "source": [
        "print('MAE: ', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE: ', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('R2: ', elastic.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWJtcaWsGTYB"
      },
      "source": [
        "De nuevo, los hiperparámetros debemos seleccionarlos con una busqueda para determinar una buena combinación."
      ]
    }
  ]
}